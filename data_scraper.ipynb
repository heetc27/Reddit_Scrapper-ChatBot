{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from psaw import PushshiftAPI\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_keywords = api.search_submissions(title='(India&President)|(Joe Biden&Politics)|(USA&Politics)|(President&elections)|(Kamala Harris&USA)', \n",
    "    filter=['id','url','author', 'title', 'score',\n",
    "     'subreddit','selftext','num_comments', 'nest_level'], # list of fields to return\n",
    "    limit = 800, # limit on the number of records returned\n",
    "    num_comments=\">20\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = api.search_submissions(subreddit=['politics'], \n",
    "    filter=['id','url','author', 'title', 'score',\n",
    "    'subreddit','selftext','num_comments'], # list of fields to return\n",
    "    limit = 400, # limit on the number of records returned\n",
    "    num_comments=\">20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_df = pd.DataFrame(list(politics))\n",
    "politics_kw_df = pd.DataFrame(list(politics_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_kw = api.search_submissions(title='(nature)|(Pollution)|(Biodegradable)|(Recycle)|(Climate Change)|(fossil fuel)|(forests)', selftext='(nature)|(Pollution)|(Biodegradable)|(Recycle)|(Climate Change)|(fossil fuel)|(forests)',\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = api.search_submissions(subreddit=['environment'],\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_df = pd.DataFrame(list(environment))\n",
    "environment_kw_df = pd.DataFrame(list(environment_kw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_kw = api.search_submissions(title='(Artificial Intelligence)|(Cybersecurity)|(Internet)|(Gadgets)|(Facebook)', selftext='(Artificial Intelligence)|(Cybersecurity)|(Internet)|(Gadgets)|(Facebook)',\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology = api.search_submissions(subreddit=['technology'],\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">25\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_kw_df = pd.DataFrame(list(technology_kw))\n",
    "technology_df = pd.DataFrame(list(technology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_kw = api.search_submissions(title='(covid)|(healthcare)|(medical)|(hospital)|(dermatologist)|(surgery)', selftext='(covid)|(healthcare)|(medical)|(hospital)|(dermatologist)|(surgery)',\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare = api.search_submissions(subreddit=['healthcare'],\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_kw_df = pd.DataFrame(list(healthcare_kw))\n",
    "healthcare_df = pd.DataFrame(list(healthcare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_kw = api.search_submissions(title='(education)|(scholarship)|(grades)|(curriculum)|(professors)',selftext='(education)|(scholarship)|(grades)|(curriculum)|(professors)',\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = api.search_submissions(subreddit=['education'],\n",
    "                                  filter=['id','url','author', 'title', 'score',\n",
    "                                          'subreddit','selftext','num_comments'], # list of fields to return\n",
    "                                  limit = 400, # limit on the number of records returned\n",
    "                                  num_comments=\">20\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_kw_df = pd.DataFrame(list(education_kw))\n",
    "education_df = pd.DataFrame(list(education))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df = pd.concat([education_df, education_kw_df])\n",
    "healthcare_df = pd.concat([healthcare_df, healthcare_kw_df])\n",
    "technology_df = pd.concat([technology_df, technology_kw_df])\n",
    "environment_df = pd.concat([environment_df, environment_kw_df])\n",
    "politics_df = pd.concat([politics_df, politics_kw_df])\n",
    "education_df['topic'] = 'Education'\n",
    "healthcare_df['topic'] = 'Healthcare'\n",
    "technology_df['topic'] = 'Technology'\n",
    "environment_df['topic'] = 'Environment'\n",
    "politics_df['topic'] = 'Politics'\n",
    "topic_df = pd.concat([politics_df.iloc[:500], environment_df.iloc[:500], technology_df.iloc[:500], healthcare_df.iloc[:500], education_df.iloc[:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "topic_df['created_at'] = topic_df['created_utc'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%dT%H:%M:%SZ'))\n",
    "all_submission = topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "topic_df['created_at'] = topic_df['created_utc'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%dT%H:%M:%SZ'))\n",
    "all_submission = topic_df\n",
    "topic_df[~topic_df['selftext'].apply(lambda x: '[deleted]' in x or '[removed]' in x)]\n",
    "all_submission = all_submission[~all_submission['title'].apply(lambda x: '[delted]' in x or '[removed]' in x)]\n",
    "all_submission['selftext'] = all_submission['selftext'].apply(lambda x: '' if '[delted]' in x or '[removed]' in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def get_comments(r_id, sub_reddit):\n",
    "  global count\n",
    "  if count % 20 == 0:\n",
    "    print(count)\n",
    "  comments_lst = list(api.search_comments(link_id=r_id, subreddit=[sub_reddit],\n",
    "                                          filter=['id','parent_id','parent_body', 'permalink','author', 'title', \n",
    "                                                  'subreddit','body','num_comments','score', 'nest_level'], limit=100))\n",
    "  count += 1\n",
    "  return list(comments_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_1 = all_submission[['id', 'subreddit']].iloc[:500].apply(lambda x: get_comments(x[0], x[1]), axis=1)\n",
    "# print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "all_comments_2 = all_submission[['id', 'subreddit']].iloc[500:1000].apply(lambda x: get_comments(x[0], x[1]), axis=1)\n",
    "# print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "all_comments_3 = all_submission[['id', 'subreddit']].iloc[1000:1500].apply(lambda x: get_comments(x[0], x[1]), axis=1)\n",
    "# print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "all_comments_4 = all_submission[['id', 'subreddit']].iloc[1500:2000].apply(lambda x: get_comments(x[0], x[1]), axis=1)\n",
    "# print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "all_comments_5 = all_submission[['id', 'subreddit']].iloc[2000:2500].apply(lambda x: get_comments(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "concat_comments = []\n",
    "for r in pd.concat([all_comments_1, all_comments_2, all_comments_3, all_comments_4, all_comments_5]):\n",
    "    try:\n",
    "        concat_comments.append(pd.DataFrame(r))\n",
    "    except:\n",
    "        print(flag)\n",
    "    flag+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([all_comments_1, all_comments_2, all_comments_3, all_comments_4, all_comments_5])\n",
    "merged_comments = pd.concat(concat_comments)\n",
    "merged_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "ignore = [1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1796, 1798, 1799, 1800, 1805, 1806, 1813, 1814, 1818, 1820, 1821, 1830, 1832]\n",
    "df_index = 0\n",
    "id_topic_map = {}\n",
    "for comments in [all_comments_1, all_comments_2, all_comments_3, all_comments_4, all_comments_5]:\n",
    "    for index, comment in comments.iteritems():\n",
    "        if df_index in ignore:\n",
    "            df_index += 1\n",
    "            continue\n",
    "#         import ipdb;ipdb.set_trace()\n",
    "        id_topic_map.update(dict(zip(range(length, length+len(comment)), [all_submission.iloc[df_index]['topic']]*len(comment))))\n",
    "        length += len(comment)\n",
    "        df_index +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comments['Topics'] = merged_comments.index.map(lambda x: id_topic_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(merged_comments.reset_index().index.map(lambda x: id_topic_map[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comments['Topics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submission.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_comments = merged_comments[~merged_comments['parent_id'].apply(lambda x: isinstance(x, int))]\n",
    "parent_ids_t1 = valid_comments[valid_comments['parent_id'].apply(lambda x: x.split(\"_\")[0] == 't1')]['parent_id']\n",
    "parent_ids_t3 = valid_comments[valid_comments['parent_id'].apply(lambda x: x.split(\"_\")[0] == 't3')]['parent_id']\n",
    "set(parent_ids_t1.apply(lambda x: x.split('_')[-1]).to_list()).intersection(set(valid_comments['id'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_not_present = set(parent_ids_t1.apply(lambda x: x.split('_')[-1]).to_list()).difference(set(valid_comments['id'].to_list()))\n",
    "set(parent_ids_t3.apply(lambda x: x.split('_')[-1]).to_list()).difference(set(all_submission['id'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "count =0 \n",
    "import time\n",
    "def get_data(url):\n",
    "    global count\n",
    "    if count % 2000 == 0:\n",
    "        time.sleep(5)\n",
    "    a = requests.get(url)\n",
    "    count += 500\n",
    "    return a.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_not_present = list(comments_not_present)\n",
    "body_list = []\n",
    "for i in range(0, len(comments_not_present), 500):\n",
    "  body_list.append(get_data(f\"https://api.pushshift.io/reddit/comment/search/?ids={','.join(comments_not_present[i:i+500])}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'id': [], 'body': []}\n",
    "for res in body_list:\n",
    "  for d in res['data']:\n",
    "    mapping['id'].append(d['id'])\n",
    "    mapping['body'].append(d.get('body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_merged = pd.concat([valid_comments, pd.DataFrame.from_dict(mapping)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_title_map = all_submission[['id', 'title']].set_index('id').to_dict()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_selftext_map = all_submission[['id', 'selftext']].set_index('id').to_dict()['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_body_map = all_comments_merged[['id', 'body']].set_index('id').to_dict()['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_merged['parent_title'] = all_comments_merged['parent_id'].apply(lambda x: id_title_map[x.split('_')[1]] if str(x).split('_')[0] == 't3' else '')\n",
    "all_comments_merged['parent_selftext'] = all_comments_merged['parent_id'].apply(lambda x: id_selftext_map[x.split('_')[1]] if str(x).split('_')[0] == 't3' else '')\n",
    "all_comments_merged['parent_body'] = all_comments_merged['parent_id'].apply(lambda x: id_body_map.get(x.split('_')[1], 'Missing') if str(x).split('_')[0] == 't1' else '')\n",
    "all_comments_merged[['body', 'parent_title', 'parent_selftext', 'parent_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_merged['parent_main_body'] = all_comments_merged[['parent_body', 'parent_title']].apply(lambda x: x[1] if x[0] == '' else x[0], axis=1)\n",
    "index_data = all_comments_merged[all_comments_merged['parent_main_body'].apply(lambda x: len(x.split()) > 0)][['body', 'parent_main_body', 'parent_selftext', 'Topics', 'parent_id']]\n",
    "index_data = all_comments_merged[all_comments_merged['body'].apply(lambda x: r'[removed]' != x and r'[deleted]' != x)][['body', 'parent_main_body', 'parent_selftext', 'Topics', 'parent_id']]\n",
    "index_data.rename(columns={'parent_main_body': 'parent_body'}, inplace=True)\n",
    "index_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "xyz = json.loads(index_data.to_json(orient = \"records\"))\n",
    "#del xyz['data']['index']\n",
    "\n",
    "json_object= json.dumps(xyz)\n",
    "#parsed = json.loads(xyz)\n",
    "#json_object = json.dumps(parsed, indent=4)\n",
    "\n",
    "with open(\"reddit_data.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = index_data.drop(['parent_selftext','parent_id'], axis=1)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('reddit_data.json')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>parent_body</th>\n",
       "      <th>parent_selftext</th>\n",
       "      <th>Topics</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scary has nothing to do with it, but a fundame...</td>\n",
       "      <td>Yes .  I’ll be blunt.  YES.  The world is a sc...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "      <td>t1_i9gz6n8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes .  I’ll be blunt.  YES.  The world is a sc...</td>\n",
       "      <td>So yes, got it</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "      <td>t1_i9gyxuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So yes, got it</td>\n",
       "      <td>Just type porn hub dot com… what do you see (h...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "      <td>t1_i9fx1c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just type porn hub dot com… what do you see (h...</td>\n",
       "      <td>So you're ok with death threats, lies, porn, e...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "      <td>t1_i67nt50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You liberals sure do fuckin hate first amendment</td>\n",
       "      <td>Biden officials worry Musk will allow Trump re...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "      <td>t3_ubtplz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144287</th>\n",
       "      <td>Voting blue to avoid red isn't a choice, it's ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>Unpopular opinion but just calling a restauran...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>Did I say \"all dogs to go extinct?\" \\n\\nThe an...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>Thank you. It’s hard to get the message out th...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>I think you posted on the wrong thread unless ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144292 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  \\\n",
       "0       Scary has nothing to do with it, but a fundame...   \n",
       "1       Yes .  I’ll be blunt.  YES.  The world is a sc...   \n",
       "2                                          So yes, got it   \n",
       "3       Just type porn hub dot com… what do you see (h...   \n",
       "4        You liberals sure do fuckin hate first amendment   \n",
       "...                                                   ...   \n",
       "144287  Voting blue to avoid red isn't a choice, it's ...   \n",
       "144288  Unpopular opinion but just calling a restauran...   \n",
       "144289  Did I say \"all dogs to go extinct?\" \\n\\nThe an...   \n",
       "144290  Thank you. It’s hard to get the message out th...   \n",
       "144291  I think you posted on the wrong thread unless ...   \n",
       "\n",
       "                                              parent_body parent_selftext  \\\n",
       "0       Yes .  I’ll be blunt.  YES.  The world is a sc...                   \n",
       "1                                          So yes, got it                   \n",
       "2       Just type porn hub dot com… what do you see (h...                   \n",
       "3       So you're ok with death threats, lies, porn, e...                   \n",
       "4       Biden officials worry Musk will allow Trump re...                   \n",
       "...                                                   ...             ...   \n",
       "144287                                                                      \n",
       "144288                                                                      \n",
       "144289                                                                      \n",
       "144290                                                                      \n",
       "144291                                                                      \n",
       "\n",
       "          Topics   parent_id  \n",
       "0       Politics  t1_i9gz6n8  \n",
       "1       Politics  t1_i9gyxuu  \n",
       "2       Politics  t1_i9fx1c4  \n",
       "3       Politics  t1_i67nt50  \n",
       "4       Politics   t3_ubtplz  \n",
       "...          ...         ...  \n",
       "144287      None        None  \n",
       "144288      None        None  \n",
       "144289      None        None  \n",
       "144290      None        None  \n",
       "144291      None        None  \n",
       "\n",
       "[144292 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "final_df = pd.DataFrame(data)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_df[\"parent_id\"]\n",
    "del final_df[\"Topics\"]\n",
    "del final_df[\"parent_selftext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>parent_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scary has nothing to do with it, but a fundame...</td>\n",
       "      <td>Yes .  I’ll be blunt.  YES.  The world is a sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes .  I’ll be blunt.  YES.  The world is a sc...</td>\n",
       "      <td>So yes, got it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So yes, got it</td>\n",
       "      <td>Just type porn hub dot com… what do you see (h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just type porn hub dot com… what do you see (h...</td>\n",
       "      <td>So you're ok with death threats, lies, porn, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You liberals sure do fuckin hate first amendment</td>\n",
       "      <td>Biden officials worry Musk will allow Trump re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129031</th>\n",
       "      <td>You’re right about people always looking for n...</td>\n",
       "      <td>My parents want me to move out or pursue furth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129032</th>\n",
       "      <td>This is a no brainer -_-</td>\n",
       "      <td>My parents want me to move out or pursue furth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129033</th>\n",
       "      <td>You're 25, you make good money, you're happy w...</td>\n",
       "      <td>My parents want me to move out or pursue furth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129034</th>\n",
       "      <td>You’re 25; not 15. Move out. Let your parents ...</td>\n",
       "      <td>My parents want me to move out or pursue furth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129035</th>\n",
       "      <td>Your parents are making you a VERY generous of...</td>\n",
       "      <td>My parents want me to move out or pursue furth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128938 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  \\\n",
       "0       Scary has nothing to do with it, but a fundame...   \n",
       "1       Yes .  I’ll be blunt.  YES.  The world is a sc...   \n",
       "2                                          So yes, got it   \n",
       "3       Just type porn hub dot com… what do you see (h...   \n",
       "4        You liberals sure do fuckin hate first amendment   \n",
       "...                                                   ...   \n",
       "129031  You’re right about people always looking for n...   \n",
       "129032                           This is a no brainer -_-   \n",
       "129033  You're 25, you make good money, you're happy w...   \n",
       "129034  You’re 25; not 15. Move out. Let your parents ...   \n",
       "129035  Your parents are making you a VERY generous of...   \n",
       "\n",
       "                                              parent_body  \n",
       "0       Yes .  I’ll be blunt.  YES.  The world is a sc...  \n",
       "1                                          So yes, got it  \n",
       "2       Just type porn hub dot com… what do you see (h...  \n",
       "3       So you're ok with death threats, lies, porn, e...  \n",
       "4       Biden officials worry Musk will allow Trump re...  \n",
       "...                                                   ...  \n",
       "129031  My parents want me to move out or pursue furth...  \n",
       "129032  My parents want me to move out or pursue furth...  \n",
       "129033  My parents want me to move out or pursue furth...  \n",
       "129034  My parents want me to move out or pursue furth...  \n",
       "129035  My parents want me to move out or pursue furth...  \n",
       "\n",
       "[128938 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df[final_df.parent_body != '']\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5944\\1109504160.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import random\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bab2f25d946bae54173ebfc9b703a11197429ffb55d07fb0b72a603c231ba36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
